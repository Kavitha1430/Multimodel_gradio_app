{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV6gTHVoWZre"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "from groq import Groq\n",
        "from huggingface_hub import login\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "# Load API keys from environment variables\n",
        "groq_api_key = os.getenv(\"groq_api_key\")\n",
        "hf_token = os.getenv(\"token\")\n",
        "image_api_key = os.getenv(\"imagetoken\")\n",
        "\n",
        "if not groq_api_key:\n",
        "    raise ValueError(\"Groq API key not found. Please ensure 'groq_api_key' is set as an environment variable.\")\n",
        "if not hf_token:\n",
        "    raise ValueError(\"Hugging Face API token not found. Please ensure 'token' is set as an environment variable.\")\n",
        "if not image_api_key:\n",
        "    raise ValueError(\"Image generation API token not found. Please ensure 'imagetoken' is set as an environment variable.\")\n",
        "\n",
        "# Initialize Groq client\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "# Authenticate Hugging Face and load MBart model and tokenizer\n",
        "login(token=hf_token)\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "\n",
        "# Stable Diffusion API details\n",
        "API_URL = \"https://api-inference.huggingface.co/models/CompVis/stable-diffusion-v1-4\"\n",
        "headers = {\"Authorization\": f\"Bearer {image_api_key}\"}\n",
        "\n",
        "# Function to transcribe audio using Groq\n",
        "def transcribe_audio(audio_path):\n",
        "    if audio_path is None:\n",
        "        return \"Please upload an audio file.\"\n",
        "    try:\n",
        "        print(\"Transcribing audio...\")\n",
        "        with open(audio_path, \"rb\") as file:\n",
        "            transcription = client.audio.transcriptions.create(\n",
        "                file=(os.path.basename(audio_path), file.read()),\n",
        "                model=\"whisper-large-v3\",\n",
        "                response_format=\"verbose_json\",\n",
        "                language=\"ta\"\n",
        "            )\n",
        "        print(f\"Transcription Response: {transcription}\")  # Debugging output\n",
        "        if hasattr(transcription, 'text'):\n",
        "            return transcription.text\n",
        "        else:\n",
        "            return \"Transcription response does not contain expected text.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Transcription error: {str(e)}\")\n",
        "        return f\"An error occurred during transcription: {str(e)}\"\n",
        "\n",
        "# Function to translate Tamil to English using MBart\n",
        "def translate_tamil_to_english(tamil_text):\n",
        "    if tamil_text is None or not tamil_text.strip():\n",
        "        return \"No text to translate\"\n",
        "    print(\"Translating text...\")\n",
        "    tokenizer.src_lang = \"ta_IN\"\n",
        "    encoded_input = tokenizer(tamil_text, return_tensors=\"pt\")\n",
        "    generated_tokens = model.generate(**encoded_input, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
        "    translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "    return translated_text\n",
        "\n",
        "# Function to generate image using Hugging Face API\n",
        "def generate_image(prompt):\n",
        "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        return f\"Error generating image: {response.status_code}, {response.text}\"\n",
        "\n",
        "#combined function\n",
        "def process_audio(audio_file, tamil_text_input):\n",
        "    transcription = None\n",
        "    translation = None\n",
        "    image = None\n",
        "\n",
        "    # Step 1: Process Audio Transcription if Audio is Provided\n",
        "    if audio_file:\n",
        "        print(f\"Received audio file: {audio_file}\")  # Debugging output for audio file path\n",
        "        try:\n",
        "            transcription = transcribe_audio(audio_file)\n",
        "            print(f\"Transcription: {transcription}\")  # Debugging output\n",
        "            if \"error\" in transcription.lower():\n",
        "                transcription = None  # Reset transcription on error\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing audio file: {e}\")\n",
        "            transcription = None  # Ensure transcription remains None on error\n",
        "\n",
        "    # Step 2: Use Tamil Text Input Directly if No Valid Audio Transcription\n",
        "    if not transcription and tamil_text_input:\n",
        "        transcription = tamil_text_input  # Use text input if audio transcription failed or wasn't provided\n",
        "        print(f\"Using Tamil Text Input: {tamil_text_input}\")  # Debugging output\n",
        "\n",
        "    # Step 3: Translate Transcription if Available\n",
        "    if transcription:\n",
        "        translation = translate_tamil_to_english(transcription)\n",
        "        print(f\"Translation: {translation}\")  # Debugging output\n",
        "\n",
        "        if \"error\" in translation.lower() or translation == \"No text to translate\":\n",
        "            translation = None  # Reset translation on error\n",
        "\n",
        "    # Step 4: Generate Image if Translation is Available\n",
        "    if translation:\n",
        "        image_bytes = generate_image(translation)\n",
        "        print(f\"Image Generation Response: {image_bytes}\")  # Debugging output\n",
        "\n",
        "        if isinstance(image_bytes, str):  # Check if there's an error message\n",
        "            image = image_bytes  # Assign error message to image output\n",
        "        else:\n",
        "            try:\n",
        "                image = Image.open(io.BytesIO(image_bytes))\n",
        "            except Exception as e:\n",
        "                image = f\"Error opening image: {str(e)}\"\n",
        "\n",
        "    # Final Output Handling\n",
        "    if transcription or translation:\n",
        "        return transcription, translation, image\n",
        "    else:\n",
        "        return \"No valid audio file or text provided\", None, None\n",
        "\n",
        "\n",
        "\n",
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=process_audio,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\", label=\"Upload Audio File (Optional)\"),\n",
        "        gr.Textbox(label=\"Enter Tamil Text (Optional)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Transcribed Text (Tamil)\"),\n",
        "        gr.Textbox(label=\"Translated Text (English)\"),\n",
        "        gr.Image(type=\"pil\", label=\"Generated Image\")\n",
        "    ],\n",
        "    title=\"Audio to Image with Translation\",\n",
        "    description=\"Upload an audio file, transcribe it, translate it to English, and generate an image based on the translation.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GQbCKczWt_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}